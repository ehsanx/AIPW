#' @title Augmented Inverse Probablity Weighting (AIPW)
#'
#' @description Define an R6Class aipw object
#'
#' @docType class
#'
#' @importFrom R6 R6Class
#'
#' @export
#'
#' @details create an AIPW object
#'
#' @return \code{AIPW} object
#'
#' @format \code{\link{R6Class}} object.
#'
AIPW <- R6::R6Class(
  "AIPW",
  portable = TRUE,
  public = list(
    #' @field n number of observations
    n = NULL,
    #' @field libs SuperLearner or sl3 libraries and their fitted objects
    libs =list(Q.SL.library=NULL,
               Q.fit = NULL,
               g.SL.library=NULL,
               g.fit = NULL,
               num_val_index = NULL),
    #' @field obs_est components for estimating the influence functions of all observations to calculate average causal effects
    obs_est = list(mu0 = NULL,
                   mu1 = NULL,
                   mu = NULL,
                   raw_p_score = NULL,
                   p_score = NULL,
                   aipw_eif1 = NULL,
                   aipw_eif0 = NULL),
    #' @field estimates risk difference, risk ratio, odds ratio and variance-covariance matrix for SE calculation
    estimates = list(RD = NULL,
                     RR = NULL,
                     OR = NULL,
                     sigma_covar = NULL),
    #' @field sl.fit a wrapper for fitting SuperLearner or sl3
    sl.fit = NULL,
    #' @field sl.predict a wrapper using \code{sl.fit} to predict
    sl.predict = NULL,
    #' @field result a matrix contains RD, RR and OR with their SE and 95%CI
    result = NULL,

    #' @description
    #' Create a new `AIPW` object.
    #'
    #' @param Y outcome (binary integer: 0 or 1)
    #' @param A exposure (binary integer: 0 or 1)
    #' @param W.Q covariates for outcome model (vector, matrix or data.frame)
    #' @param W.g covariates for exposure model (vector, matrix or data.frame)
    #' @param Q.SL.library SuperLearner libraries or sl3 learner object (Lrnr_base) for outcome model
    #' @param g.SL.library SuperLearner libraries or sl3 learner object (Lrnr_base) for exposure model
    #' @param k_split number of splitting (integer; range: from 1 to number of observation-1):
    #'   if k_split=1, no sample splitting;
    #'   if k_split>1, use similar technique of cross-validation
    #'   (e.g., k_split=5, use 4/5 of the data to estimate and the remaining 1/5 leftover to predict)
    #' @param verbose whether to show progression bar and print the result (logical; Default = FALSE)
    #'
    #' @return A new `AIPW` obejct
    #'
    #' @examples
    #' library(SuperLearner)
    #' aipw_sl <- AIPW$new(Y=rbinom(100,1,0.5), A=rbinom(100,1,0.5),
    #'                     W.Q=rbinom(100,1,0.5), W.g=rbinom(100,1,0.5),
    #'                     Q.SL.library="SL.mean",g.SL.library="SL.mean",
    #'                     k_split=1,verbose=FALSE)
    initialize = function(Y=NULL, A=NULL,W.Q=NULL, W.g=NULL,
                          Q.SL.library=NULL,g.SL.library=NULL,
                          k_split=1,verbose=FALSE){
      #save input into private fields
      private$Y=Y
      private$A=A
      private$Q.set=cbind(A, as.data.frame(W.Q))
      private$g.set=as.data.frame(W.g)
      private$k_split=k_split
      private$verbose=verbose
      #check data length
      if (!(length(private$Y)==length(private$A) & length(private$Y)==dim(private$Q.set)[1] & length(private$A)==dim(private$g.set)[1])){
        stop("Please check the dimension of the data")
      }
      #determine SuperLearner or sl3 and change accordingly
      if (is.character(Q.SL.library) & is.character(g.SL.library)) {
        if (any(grepl("SL.",Q.SL.library)) & any(grepl("SL.",g.SL.library))){
          #change future package loading
          private$sl.pkg <- "SuperLearner"
          #change wrapper functions
          self$sl.fit = function(Y, X, SL.library){
            fit <- SuperLearner::SuperLearner(Y = Y, X = X, SL.library = SL.library, family="binomial")
            return(fit)
          }
          self$sl.predict = function(fit, newdata){
            pred <- as.numeric(predict(fit,newdata = newdata)$pred)
            return(pred)
          }
        } else{
          stop("Input Q.SL.library and/or g.SL.library is not a valid SuperLearner library")
        }
      } else if (any(class(Q.SL.library) == "Lrnr_base") & any(class(g.SL.library) == "Lrnr_base")) {
        #only using Stack in sl3 will return estimates of each library separately
        if (any(class(Q.SL.library) == "Stack") & any(class(g.SL.library) == "Stack")){
          warning("Only using sl3::Stack may cause problem. Please consider using metalearners for the stacked libraries!")
        } else {
          #change wrapper functions
          self$sl.fit = function(X, Y, SL.library){
            dat <- data.frame(cbind(Y,X))
            dat_colnames <- colnames(dat)
            task <- sl3::sl3_Task$new(dat, covariates = colnames(dat)[-1],
                                      outcome = colnames(dat)[1], outcome_type = "binomial"
            )
            fit <- SL.library$train(task)
            return(fit)
          }
          self$sl.predict = function(fit, newdata){
            new_task <- sl3::sl3_Task$new(newdata, covariates = colnames(newdata))
            pred <- fit$predict(new_task)
            return(pred)
          }
        }
      } else {
        stop("Input Q.SL.library and/or g.SL.library is not a valid SuperLearner/sl3 library")
      }

      #input sl libraries
      self$libs$Q.SL.library=Q.SL.library
      self$libs$g.SL.library=g.SL.library

      #setup
      self$n <- length(private$Y)
      self$obs_est$mu0 <- rep(NA,self$n)
      self$obs_est$mu1 <- rep(NA,self$n)
      self$obs_est$mu <- rep(NA,self$n)
      self$obs_est$raw_p_score <- rep(NA,self$n)
      #validation set index
      self$libs$num_val_index <- rep(NA,self$n)

      #check k_split value
      if (private$k_split<1 | private$k_split>=self$n){
        stop("k_split is not valid")
      }
      #check verbose value
      if (!is.logical(private$verbose)){
        stop("verbose is not valid")
      }
      #check if SuperLearner and/or sl3 library is loaded
      if (!any(names(sessionInfo()$otherPkgs) %in% c("SuperLearner","sl3"))){
        warning("Either `SuperLearner` or `sl3` package is not loaded.")
      }
      #check if future.apply is loaded otherwise lapply would be used.
      if (any(names(sessionInfo()$otherPkgs) %in% c("future.apply"))){
        private$.f_lapply = function(iter,func) future.apply::future_lapply(iter,func,future.seed = T,future.packages = private$sl.pkg)
      }else{
        private$.f_lapply = function(iter,func) lapply(iter,func)
        }
    },
    #' @description
    #' Fitting the data into the `AIPW` object with/without sample splitting to estimate the influence functions
    #'
    #' @return A fitted `AIPW` obejct
    #'
    #' @examples
    #' library(SuperLearner)
    #' aipw_sl <- AIPW$new(Y=rbinom(100,1,0.5), A=rbinom(100,1,0.5),
    #'                     W.Q=rbinom(100,1,0.5), W.g=rbinom(100,1,0.5),
    #'                     Q.SL.library="SL.mean",g.SL.library="SL.mean",
    #'                     k_split=1,verbose=FALSE)
    #' aipw_sl$fit()
    fit = function(){
      #create index for sample splitting
      k_index <- sample(rep(1:private$k_split,ceiling(self$n/private$k_split))[1:self$n],replace = F)
      #progress bar setup
      progressr::handlers("progress")
      iter <- 1:private$k_split
      progressr::with_progress(enable = private$verbose,{
        #progress bar
        pb <- progressr::progressor(along = iter)
        #parallelization with future.apply
        fitted <- private$.f_lapply(
          iter=iter,
          func=function(i,...){
            #check whether to split samples
            if (private$k_split==1){
              train_index <- validation_index <- k_index==i
            } else{
              train_index <- k_index!=i
              validation_index <- k_index==i
            }

            num_val_index <- which(validation_index)
            names(num_val_index) <- rep(i,length(num_val_index))
            #split the sample based on the index
            #Q outcome set
            train_set.Q <- private$Q.set[train_index,]
            validation_set.Q <- private$Q.set[validation_index,]
            #g exposure set
            train_set.g <- data.frame(private$g.set[train_index,])
            validation_set.g <- data.frame(private$g.set[validation_index,])
            colnames(train_set.g)=colnames(validation_set.g)=colnames(private$g.set) #make to g df colnames consistent

            #Q model(outcome model: g-comp)
            #fit with train set
            Q.fit <- self$sl.fit(Y = private$Y[train_index],
                                           X = train_set.Q,
                                           SL.library = self$libs$Q.SL.library)
            # predict on validation set
            mu0 <- self$sl.predict(Q.fit,newdata=transform(validation_set.Q, A = 0)) #Q0_pred
            mu1  <- self$sl.predict(Q.fit,newdata=transform(validation_set.Q, A = 1)) #Q1_pred

            #g model(exposure model: propensity score)
            # fit with train set
            g.fit <- self$sl.fit(Y=private$A[train_index],
                                           X=train_set.g,
                                           SL.library = self$libs$g.SL.library)
            # predict on validation set
            raw_p_score  <- self$sl.predict(g.fit,newdata = validation_set.g)  #g_pred

            pb(sprintf("Iteration=%g/%g", i,private$k_split))
            output <- list(num_val_index,Q.fit,mu0,mu1,g.fit,raw_p_score)
            names(output) <- c("num_val_index","Q.fit","mu0","mu1","g.fit","raw_p_score")
            return(output)
          })
        })

      #store fitted values from future to member variables
      self$libs$num_val_index <- unlist(lapply(fitted,function(x) x$num_val_index))
      self$libs$Q.fit <- lapply(fitted,function(x) x$Q.fit)
      self$libs$g.fit <- lapply(fitted,function(x) x$g.fit)
      self$obs_est$mu0[self$libs$num_val_index] <- unlist(lapply(fitted,function(x) x$mu0))
      self$obs_est$mu1[self$libs$num_val_index] <- unlist(lapply(fitted,function(x) x$mu1))
      self$obs_est$raw_p_score[self$libs$num_val_index] <- unlist(lapply(fitted,function(x) x$raw_p_score))

      self$obs_est$mu  <- (self$obs_est$mu0*(1-private$A) + self$obs_est$mu1*(private$A)) #Q_pred

      if (private$verbose){
        cat("Done!\n")
      }

      invisible(self)
    },
    #' @description
    #' Calculate average causal effects in RD, RR and OR in the fitted `AIPW` obejct with the estimated influence functions
    #'
    #' @param g.bound value between \[0,1\] at which the propensity score should be truncated. Defaults to 0.025.
    #'
    #' @return An `AIPW` obejct with average treatment effect estimations in RD, RR and OR
    #'
    #' @examples
    #' library(SuperLearner)
    #' aipw_sl <- AIPW$new(Y=rbinom(100,1,0.5), A=rbinom(100,1,0.5),
    #'                     W.Q=rbinom(100,1,0.5), W.g=rbinom(100,1,0.5),
    #'                     Q.SL.library="SL.mean",g.SL.library="SL.mean",
    #'                     k_split=1,verbose=FALSE)$fit()
    #' aipw_sl$calculate_result(g.bound=0.025)
    calculate_result = function(g.bound=0.025){
      #p_score truncation
      private$g.bound=g.bound
      #check g.bound value
      if (!is.numeric(private$g.bound)){
        stop("g.bound must be a numeric value")
      } else if (private$g.bound>1|private$g.bound<0){
        stop("g.bound must between 0 and 1")
      }
      self$obs_est$p_score <- private$.bound(self$obs_est$raw_p_score)

      #AIPW est
      self$obs_est$aipw_eif1 <- (as.numeric(private$A==1)/self$obs_est$p_score)*(private$Y - self$obs_est$mu) + self$obs_est$mu1
      self$obs_est$aipw_eif0 <- (as.numeric(private$A==0)/self$obs_est$p_score)*(private$Y - self$obs_est$mu) + self$obs_est$mu0

      Z_norm <- sqrt(self$n)

      ## risk difference
      self$estimates$RD <- private$get_RD(self$obs_est$aipw_eif1, self$obs_est$aipw_eif0, Z_norm)

      ## var-cov mat for rr and or calculation
      self$estimates$sigma_covar <- private$get_sigma_covar(self$obs_est$aipw_eif0,self$obs_est$aipw_eif1)

      ## risk ratio
      self$estimates$RR <- private$get_RR(self$obs_est$aipw_eif1,self$obs_est$aipw_eif0, self$estimates$sigma_covar, Z_norm)

      ## odds ratio
      self$estimates$OR <- private$get_OR(self$obs_est$aipw_eif1,self$obs_est$aipw_eif0, self$estimates$sigma_covar, Z_norm)

      self$result <- cbind(matrix(c(self$estimates$RD,self$estimates$RR,self$estimates$OR),nrow=3,byrow=T),self$n)
      colnames(self$result) <- c("Estimate","SE","95% LCL","95% UCL","N")
      row.names(self$result) <- c("Risk Difference","Risk Ratio", "Odds Ratio")
      if (private$verbose){
        print(self$result,digit=3)
      }
      invisible(self)
    },
    #' @description
    #' Plot and check the balance of propensity scores by exposure status
    #'
    #' @return A density plot of propensity scores by exposure status (`ggplot2::geom_density`)
    #' @examples
    #' library(SuperLearner)
    #' library(ggplot2)
    #' aipw_sl <- AIPW$new(Y=rbinom(100,1,0.5), A=rbinom(100,1,0.5),
    #'                     W.Q=rbinom(100,1,0.5), W.g=rbinom(100,1,0.5),
    #'                     Q.SL.library="SL.mean",g.SL.library="SL.mean",
    #'                     k_split=1,verbose=FALSE)$fit()
    #' #before average treatment effect calculation
    #' aipw_sl$plot.p_score()
    #' #after calculation
    #' aipw_sl$calculate_result(g.bound=0.025)$plot.p_score()
    plot.p_score = function(){
      #check if ggplot2 library is loaded
      if (!any(names(sessionInfo()$otherPkgs) %in% c("ggplot2"))){
        stop("`ggplot2` package is not loaded.")
      }
      #input check
      if (any(is.na(self$obs_est$raw_p_score))){
        stop("Propensity scores are not estimated.")
      } else if (is.null(self$obs_est$p_score)) {
      #p_score before truncation (estimated ps)
      plot_data = data.frame(A = factor(private$A),
                             p_score= self$obs_est$raw_p_score,
                             trunc = "Not truncated")
        message("ATE has not been calculated.")
      } else {
        plot_data = rbind(data.frame(A = factor(private$A),
                               p_score= self$obs_est$raw_p_score,
                               trunc = "Not truncated"),
                          data.frame(A = factor(private$A),
                               p_score= self$obs_est$p_score,
                               trunc = "Truncated"))
      }
      g.plot <-  ggplot2::ggplot(data = plot_data,ggplot2::aes(x = p_score, group = A, color = A, fill=A)) +
        ggplot2::geom_density(alpha=0.5) +
        ggplot2::scale_x_continuous(limits = c(0,1)) +
        ggplot2::facet_wrap(~trunc) +
        ggtitle("Propensity scores by exposure status") +
        theme_bw()
      print(g.plot)
    }
  ),
  private = list(
    #input
    Y=NULL,
    A=NULL,
    Q.set=NULL,
    g.set=NULL,
    k_split=NULL,
    verbose=NULL,
    g.bound=NULL,
    sl.pkg =NULL,
    #private methods
    #lapply or future_lapply
    .f_lapply =NULL,
    #Use individaul estimates (obs_est$aipw_eif0 & obs_est$aipw_eif0 ) to calcualte RD, RR and OR with SE and 95CI%
    get_RD = function(aipw_eif1,aipw_eif0,Z_norm){
      est <- mean(aipw_eif1 - aipw_eif0)
      se <- stats::sd(aipw_eif1 - aipw_eif0)/Z_norm
      ci <- get_ci(est,se,ratio=F)
      output = c(est, se, ci)
      names(output) = c("Estimate","SE","95% LCL","95% UCL")
      return(output)
    },
    get_RR = function(aipw_eif1,aipw_eif0,sigma_covar,Z_norm){
      est <- mean(aipw_eif1)/mean(aipw_eif0)
      se <- sqrt((sigma_covar[1,1]/(mean(aipw_eif0)^2)) -
                   (2*sigma_covar[1,2]/(mean(aipw_eif1)*mean(aipw_eif0))) +
                   (sigma_covar[2,2]/mean(aipw_eif1)^2) -
                   (2*sigma_covar[1,2]/(mean(aipw_eif1)*mean(aipw_eif0))))/Z_norm
      ci <- get_ci(est,se,ratio=T)
      output = c(est, se, ci)
      names(output) = c("Estimate","SE","95% LCL","95% UCL")
      return(output)
    },
    get_OR = function(aipw_eif1,aipw_eif0,sigma_covar,Z_norm){
      est <- (mean(aipw_eif1)/(1-mean(aipw_eif1))) / (mean(aipw_eif0)/(1-mean(aipw_eif0)))
      se <- sqrt((sigma_covar[1,1]/((mean(aipw_eif0)^2)*(mean(1-aipw_eif0)^2))) -
                   (2*sigma_covar[1,2]/(mean(aipw_eif1)*mean(aipw_eif0)*mean(1-aipw_eif1)*mean(1-aipw_eif0))) +
                   (sigma_covar[2,2]/((mean(aipw_eif1)^2)*(mean(1-aipw_eif1)^2))) -
                   (2*sigma_covar[1,2]/(mean(aipw_eif1)*mean(aipw_eif0)
                                        *mean(1-aipw_eif1)*mean(1-aipw_eif0))))/Z_norm
      ci <- get_ci(est,se,ratio=T)
      output = c(est, se, ci)
      names(output) = c("Estimate","SE","95% LCL","95% UCL")
      return(output)
    },
    get_sigma_covar = function(aipw_eif0,aipw_eif1){
      mat <- matrix(c(stats::var(aipw_eif0),
                      stats::cov(aipw_eif0,aipw_eif1),
                      stats::cov(aipw_eif1,aipw_eif0),
                      stats::var(aipw_eif1)),nrow=2)
      return(mat)
    },
    #setup the bounds for the propensity score to ensure the balance
    .bound = function(p_score,bound = private$g.bound){
      res <- base::ifelse(p_score<bound,bound,
                          base::ifelse(p_score>(1-bound),(1-bound),p_score))
      return(res)
    }
  )
)
